---
title: "Assessing the Impact of Airbnb's Plus Program: A Fixed Effects Analysis with Cross-Sectional and Time-Series Dimensions"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    toc: false
    number_sections: false
  html_document:
    toc: false
    df_print: paged
fontsize: 12pt
geometry: margin=1in
linestretch: 1.5
mainfont: Times New Roman
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE)
Sys.setlocale("LC_TIME","en_US.UTF-8")

library(tidyverse)
library(gridExtra)
library(lubridate)
library(kableExtra)
library(infer)
library(janitor)
library(stargazer)
library(plm) 
library(lmtest)
library(GGally)
library(grid)
library(dplyr)
library(performance)
library(car)

data <- read_csv("airbnb_data_clean.csv")
```
# Introduction 
This study builds on prior research exploring the Airbnb Plus program's impact on **booking_rate**, which found no significant effect. Addressing limitations such as unobserved factors and missing fixed effects, it uses a Fixed Effects model to estimate the program's causal effect by comparing treated cities (Nashville, New Orleans, Washington DC, Denver) to controls, accounting for **employment_rate**, **price_mean**, and **year_built_to_now**. Additionally, the study examines the impact of the program on **listing_avg_review**, testing whether it increases customer satisfaction in treated cities compared to controls, after controlling for city-specific and time-specific effects.

# 1. Refining Hypotheses

The **first hypothesis** is, therefore, the following:

- $H_0:$ The introduction of the Airbnb Plus program does not significantly affect booking rates in treated cities compared to control cities, after accounting for city-specific and time-specific effects (i.e., *β3 = 0*, where β3 is the coefficient of the interaction term).

- $H_a:$ The introduction of the Airbnb Plus program does significantly affect booking rates in treated cities compared to control cities, after accounting for city-specific and time-specific effects (i.e.,*β3 ≠ 0*).
\[
\text{booking\_rate}_{it} = \alpha_i + \gamma_t + \beta_3 (Plus_i \times Treated_i) + \epsilon_{it}
\]
The **second hypothesis** is formulated as follows:

- $H_0:$ The introduction of the Airbnb Plus program does not increase listing average reviews in treated cities compared to control cities, after accounting for city-specific and time-specific effects (i.e., *β3 ≤ 0*, where β3 is the coefficient of the interaction term).

- $H_a:$ The introduction of the Airbnb Plus program increases listing average reviews in treated cities compared to control cities, after accounting for city-specific and time-specific effects (i.e., *β3 > 0*).
\[
\text{listing\_avg\_review}_{it} = \alpha_i + \gamma_t + \beta_3 (Plus_i \times Treated_i) + \epsilon_{it}
\]
Where:

- **\(\alpha_i\)**: City fixed effects

- **\(\gamma_t\)**: Time fixed effects, affecting all cities equally

- **group**: Indicator variable for whether cities are in the **treated** or **control** group

- **\(\beta_3 (\text{Plus} \times \text{Treated})\)**: Interaction term capturing the DiD effect

- \(\epsilon_{it}\): Error term, capturing random noise or unobserved factors varying across cities and over time

# 2. Dataset Overview, Data Quality & Model-Free Investigation

As the Airbnb Plus program is implemented in five cities, five others will serve as controls. San Francisco, part of the pilot phase, is excluded to avoid bias. The dataset includes `r nrow(data)` observations across `r ncol(data)` variables, covering `r n_distinct(data$zipcode)` zip codes in `r n_distinct(data$city_number)` U.S. cities from August 2017 (`timeperiod` = `r min(data$timeperiod)`) to October 2019 (`timeperiod` = `r max(data$timeperiod)`). Key variables include **performance metrics** (`booking_rate`, `listing_avg_reviews`) and **secondary variables** (`zipcode`, `timeperiod`, `city_number`, `policy_entry`, `employment_rate`, `price_mean`, `year_built_to_now`). Additional variables created for analysis are:  
- **`city_name`**: maps `city_number` to city names or *Others*.  
- **`date`**: converts `timeperiod` to year-month format.  
- **`group`**: distinguishes treated and control cities.  
- **`time`**: flags pre- and post-Plus program periods.

```{r}
cities_analysis <- data %>% group_by(city_number) %>% summarize(plus = sum(policy_entry))
# If plus == 0 then plus program was never implemented in that city if != 0 then plus program was implemented at some point in time period

# Cities with plus program
data_with_plus <- data %>% filter(policy_entry > 0)
# Cities: 4, 5, 6, 9 and 11

# Categorical variable with city name - Identified by searching zipcodes online
data <- data %>% mutate(city_name = if_else(city_number == 4, "Denver", 
                                    if_else(city_number == 5, "Nashville", 
                                    if_else(city_number == 6, "New Orleans", 
                                    if_else(city_number == 9, "San Francisco", 
                                    if_else(city_number == 11, "Washington DC", "Others"))))))

# Transforming time period to a more readable date
data$date = as.Date(as.Date("2017-08-01") + months(data$timeperiod - 8), "%Y %m")
rm(cities_analysis)
```
  
```{r}
# Selecting only the variables that are important for our research
data_test <- data %>% dplyr::select(booking_rate, zipcode, timeperiod, date, city_number, city_name, policy_entry, employment_rate, price_mean, listing_avg_review, year_built_to_now)

rm(data_with_plus)
```

To begin assessing the quality of the data-set, the following shows a quick inspection, showing the structure of the data.

```{r}
kable(head(data_test), caption = "Preview of the data") %>%
  kable_styling(latex_options = c("scale_down"), font_size = 6)
```

```{r}
#Creating treated vs control group variable for diff in diff framework

data_test <- data_test %>%
  filter(city_name != "San Francisco") %>%
  group_by(city_name) %>%
  mutate(group = if_else(sum(policy_entry) == 0, "Control", "Treated")) %>%
  ungroup() %>%
  mutate(group = factor(group, levels = c("Control", "Treated")),
         time = if_else(timeperiod < 22, "Before", "After"),
         time = factor(time, levels = c("Before", "After")))
```

### Missing Values

```{r}
# For listing_avg_review, -1 values will be dropped
data_test <- data_test[data_test$listing_avg_review != -1, ]

# For price_mean, 0 values will be dropped
data_test <- data_test[data_test$price_mean != 0, ]

# Dropping NAs for city_number
data_test <- data_test %>%
  filter(!is.na(city_number))

# Replacing NAs with mean for all relevant variables
data_clean <- data_test %>%
  group_by(city_number) %>%
  mutate(
    # Replace NAs in booking_rate with the group mean
    mean_booking = mean(booking_rate, na.rm = TRUE),
    booking_rate = ifelse(is.na(booking_rate), mean_booking, booking_rate),
    
    # Replace NAs in employment_rate with the group mean
    mean_employment = mean(employment_rate, na.rm = TRUE),
    employment_rate = ifelse(is.na(employment_rate), mean_employment, employment_rate),
    
    # Replace NAs in price_mean with the group mean
    mean_price_mean = mean(price_mean, na.rm = TRUE),
    price_mean = ifelse(is.na(price_mean), mean_price_mean, price_mean), 
  
    # Replace NAs in listing_avg_reviews with the group mean
    mean_listing_avg = mean(listing_avg_review, na.rm = TRUE),
    listing_avg_review = ifelse(is.na(listing_avg_review), mean_listing_avg, listing_avg_review),

    # Replace NAs in year_built_to_now with the group mean
    mean_year_built = mean(year_built_to_now, na.rm = TRUE),
    year_built_to_now = ifelse(is.na(year_built_to_now), mean_year_built, year_built_to_now)) %>%
  
  dplyr::select(-mean_booking, -mean_employment, -mean_price_mean, -mean_listing_avg, -mean_year_built) %>%
  ungroup()
```


During the data cleaning process, a total of `r sum(is.na(data_test))` missing values were identified across various variables, including **booking_rate**, **employment_rate**, **price_mean**, **listing_avg_review**, **year_built_to_now**. For **booking_rate**, both zero and negative values were retained, as the variable reflects the ratio of bookings (positive values) to cancellations (negative values). For **listing_avg_review**, negative values (-1) were treated as an indicator for a booking having no reviews yet due to being new. These were treated as non-random missing values. For this reason, instead of being replaced with the mean, they were dropped to not introduce bias to the research. Instead, actual missing values were treated as random ones and were replace with the mean of the city. Similarly, for **price_mean**, zeroes were found and were dropped as these were likely input because there were no listing prices in that specific zip code to compute the price mean. The other variables did not have any zeroes or negative values, their actual missing values were treated as random missing data and replaced with their city mean. This approach was chosen to prevent the removal of rows, which could have introduced gaps in time for certain zip codes and cities. By using city-specific means, we minimized bias and retained as much relevant data as possible.

Each variable was carefully examined, and it was found that most missing values were NAs (rather than NaN or zeros). The imputation strategy allowed for the preservation of data integrity, ensuring minimal disruption to the overall data set. The cleaned data was then summarized, confirming the successful handling of missing values and providing a solid foundation for further analysis.

### Outliers

```{r , fig.height=3}
# Box Plots for metric variables
plot_boxplot = function(var, title){
  ggplot(data_clean, aes(x = !!sym(var))) +
    geom_boxplot(fill = I("lightblue3"), color = I("black")) +
    coord_flip() + 
    labs(x = paste(title)) + 
    theme_bw() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank()) +
    theme(plot.title = element_text(size = 2))
}

plot1 = plot_boxplot("booking_rate", "Booking Rate")
plot2 = plot_boxplot("employment_rate", "Employment Rate")
plot3 = plot_boxplot("listing_avg_review", "listing_avg_review")
plot4 = plot_boxplot("price_mean", "price_mean")
plot5 = plot_boxplot("year_built_to_now", "year_built_to_now")

grid.arrange(plot1, plot2, plot3, plot4, plot5, ncol = 3)
rm(plot1, plot2, plot3, plot4, plot5)
```
All variables show significant of outliers, except for **year_built_to_now**. **Listing_avg_review** and **employment_rate** outliers will be replaced with the mean for their respective city number since they're likely caused by either a very negative review or a random error, like an employment rate below 60% for `r data_clean %>% filter(employment_rate < 0.6) %>% dplyr::select(zipcode)` which is the zipcode for Queens County, NY. After a brief online research, employment rates in this area were found to be unlikely to drop below this threshold. Furthermore, listing average reviews and booking rate will be truncated using 5th and 95th percentiles, retaining only 90% of the data which will be enough to test the hypotheses. Price mean instead will be log-transformed to deal with its outliers.

```{r}
#Finding which city has employment rate outliers
low_er_city_number <- data_clean %>% filter(employment_rate < 0.6) %>% dplyr::select(city_number)

#Getting mean employment_rate for that city
mean_7_er <- data_clean %>% filter(city_number == 7) %>% summarise(mean_er = mean(employment_rate))

#Inputting mean in place of outlier
data_clean <- data_clean %>%
  mutate(
    employment_rate = ifelse(employment_rate < 0.6 & city_number == 7, mean_7_er$mean_er, employment_rate))

rm(low_er_city_number, mean_7_er)
```

```{r}
#Finding which cities has listing avg reviews outliers
low_lar_city_numbers <- data_clean %>% filter(listing_avg_review < 70) %>% dplyr::select(city_number)

#Getting mean listing_avg_review for those cities
mean_low_lar_1 <- data_clean %>% filter(city_number == 1) %>% summarise(mean_low_lar = mean(listing_avg_review))
mean_low_lar_7 <- data_clean %>% filter(city_number == 7) %>% summarise(mean_low_lar = mean(listing_avg_review))
mean_low_lar_11<- data_clean %>% filter(city_number == 11) %>% summarise(mean_low_lar = mean(listing_avg_review))
mean_low_lar_10<- data_clean %>% filter(city_number == 10) %>% summarise(mean_low_lar = mean(listing_avg_review))
mean_low_lar_6<- data_clean %>% filter(city_number == 6) %>% summarise(mean_low_lar = mean(listing_avg_review))

#Inputting mean in place of outlier
data_clean <- data_clean %>%
  mutate(
    listing_avg_review = ifelse(
      listing_avg_review < 70 & city_number == 7, 
      mean_low_lar_7$mean_low_lar, 
      ifelse(
        listing_avg_review < 70 & city_number == 11, 
        mean_low_lar_11$mean_low_lar,
        ifelse(
          listing_avg_review < 70 & city_number == 1,
          mean_low_lar_1$mean_low_lar,
          ifelse(
            listing_avg_review < 70 & city_number == 10,
            mean_low_lar_10$mean_low_lar,
            ifelse(
              listing_avg_review < 70 & city_number == 6,
              mean_low_lar_6$mean_low_lar,
              listing_avg_review))))))

rm(low_lar_city_numbers, mean_low_lar_1, mean_low_lar_7, mean_low_lar_11, mean_low_lar_10, mean_low_lar_6)
```

```{r}
#Truncating booking rate using 5th and 95th percentiles, retaining 90% of data
data_clean <- data_clean %>%
  filter(booking_rate >= quantile(booking_rate, 0.05) &
         booking_rate <= quantile(booking_rate, 0.95))

#Truncating listing avg reviews using 5th and 95th percentiles, retaining 90% of data
data_clean <- data_clean %>%
  filter(listing_avg_review >= quantile(listing_avg_review, 0.05) &
         listing_avg_review <= quantile(listing_avg_review, 0.95))

#Log Transformation of Price Mean
data_clean <- data_clean %>% mutate(log_price_mean = log(price_mean)) %>% dplyr::select(-price_mean)
```

```{r, results = "hide"}
#Converting dataset to a panel structure for FD and FE models 
tb.clean <- as_tibble(data_clean)
names(tb.clean)
pdf.clean <- pdata.frame(tb.clean, index = c('city_name', 'time'))

#Check if panel data set is balanced
is.pbalanced(pdf.clean)
```

```{r , results = 'asis'}
stargazer(data.frame(pdf.clean),
          type = "latex", 
          header = FALSE , 
          font.size = "small", 
          median = TRUE,
          iqr = TRUE, 
          title = "Summary Statistics for Final Data Set",
          table.layout = "lccc", 
          out = "stargazer_output.tex")
```
\newpage
A panel data set was created for the DiD regression analysis, allowing to compare changes before and after the introduction of the Airbnb Plus program across multiple cities. The two dimensions of the data are **city_name** and **time**, where the former represents the entities and the latter denotes the periods under study. The panel data is balanced, meaning each city has data for all time periods.

## Model Free investigation

This section presents a model-free investigation using a Difference-in-Differences (DiD) approach to assess the impact of Airbnb Plus. We visualize booking rates and listing reviews before and after the program’s introduction for treated and control cities. This analysis offers an intuitive understanding of the program's effects.

```{r, fig.height = 3}
plot1 <- ggplot(data = data_clean, aes(x = booking_rate, fill = factor(group))) +
  geom_histogram(binwidth = 0.05, alpha = 0.7) +
  facet_wrap(~ time, scales = "free_y") +
  labs(
    x = "Booking Rate",
    y = "Frequency",
    fill = "Group",
    title = "Distribution of Booking Rate by Time"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12, face = "bold"),
    axis.text = element_text(size = 10),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    legend.position = "top",
    panel.spacing = unit(1, "lines")
  )
plot2 <- ggplot(data = data_clean, aes(x = listing_avg_review, fill = factor(group))) +
  geom_histogram(binwidth = 0.8, alpha = 0.7) +
  facet_wrap(~ time, scales = "free_y") +
  labs(
    x = "Listing Avg Reviews",
    y = "Frequency",
    fill = "Group",
    title = "Distribution of Listing Avg Reviews by Time"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 12, face = "bold"),
    axis.text = element_text(size = 10),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    legend.position = "top",
    panel.spacing = unit(1, "lines")
  )
plot1
plot2
```

The distributions of **booking_rate** and **listing_avg_review** remain approximately normal before and after implementing the program. Listing avg reviews appear to be slightly left-skewed. In both cases, the control groups have more observations than the treated group. The differences in group sizes may lead to heteroscedasticity, impacting the precision of the interaction term estimates.

```{r, results = "hide"}
# Summary of mean booking rate
means_data <- data_clean %>%
  group_by(group, time) %>% # Group by treated and period
  summarise(
    mean_booking_rate = mean(booking_rate, na.rm = TRUE),
    mean_listing_avg = mean(listing_avg_review, na.rm = TRUE)
  ) 

means_data %>% kable(caption = "Mean Booking Rate and Listing Avg Reviews by Group and Time") %>%
  kable_styling(font_size = 10)
```

```{r, fig.height = 3, fig.width = 8}
#Boxplot of Before/After booking rates treated vs control group
plot1 <- ggplot(data = data_clean, aes(x = time, y = booking_rate, fill = factor(group))) + 
  geom_boxplot() +
  labs(x = "Time", y = "Booking Rate", fill="Group", title = "Booking Rate by Time and Group") +
  theme(plot.title = element_text(size = 10))

plot2 <- ggplot(data = data_clean, aes(x = time, y = listing_avg_review, fill = factor(group))) + 
  geom_boxplot() +
  labs(x = "Time", y = "Listing Avg Review", fill="Group", title = "Listing Avg Reviews by Time and Group") +
  ylim(90, 100) +
  theme(plot.title = element_text(size = 10))

grid.arrange(plot1, plot2, ncol = 2)
```

The boxplots provides a detailed view of the distributions before and after the program's introduction, showing that booking rates in treated cities maintain similar median levels with less variance compared to the control group, while average review ratings for treated cities consistently remain higher but with limited post-treatment changes.

```{r, fig.height = 3, fig.width = 7}
# Diff-in-diff plot
plot1 <- ggplot(data = means_data, 
       aes(x = time, y = mean_booking_rate, group = group, color = group)) + 
  geom_point() + 
  geom_line() +
  ylim(0.15, 0.3) + 
   labs(
    title = "DiD Plot: Mean Booking Rate",
    x = "Time",
    y = "Mean Booking Rate",
    color = "Group"
  ) + theme(plot.title = element_text(size = 10))
plot2 <- ggplot(data = means_data, 
       aes(x = time, y = mean_listing_avg, group = group, color = group)) + 
  geom_point() + 
  geom_line() +
  ylim(90, 100) +
  labs(
    title = "DiD Plot: Mean Listing Avg Reviews",
    x = "Time",
    y = "Mean Listing Avg Reviews",
    color = "Group"
  ) + theme(plot.title = element_text(size = 10))

grid.arrange(plot1, plot2, ncol = 2)
```

The line graphs show the trends over time for booking rates and average review ratings. The first graph highlights a divergence in booking rates where treated cities stabilize while control cities decline. The graph for the average reviews shows the opposite as the gap between the two groups is narrowing. Together, these visualizations suggest that the Airbnb Plus program's impact is more noticeable in stabilizing booking rates than in influencing average reviews.

# 3. Regression Analysis: Estimating the Impact of Airbnb Plus

In this section, we apply regression analysis to estimate the impact of the Airbnb Plus program, controlling for city-specific factors using fixed city effects. By incorporating fixed effects, we account for unobserved heterogeneity across cities that could influence the outcome variables, such as booking rate and average reviews. This approach helps isolate the effect of Airbnb Plus from other city-level influences, providing a more robust estimation of the program’s impact. The Fixed Effects results for **booking_rates** show that the Plus program has a marginally significant effect on booking rates for treated cities after its implementation. After including control variables, the interaction term loses its significance, meaning that the Plus program's effect on booking rates may be explained by factors like property characteristics (*year_built_to_now*) or specific rental market conditions (*log_price_mean*), rather than the program itself. For instance, it can be observed that for every unit increase in *price_mean*, *booking_rate* decreases by 0.023 units, while every unit increase in *year_built_to_now* leads to 0.01 pp increase in *booking_rate*. Ultimately, there is no evidence that the interaction effect is different from zero, so we **fail to reject** the null hypothesis. The Fixed Effects results for **listing_avg_reviews** show a **significantly negative** interaction term before and after including the control variables. Contrary to expectations, the Plus program may have had an adverse effect on average reviews in treated cities, potentially due to unintended consequences or negative customer experiences associated with the program. The observed effect seems to not be driven by confounding factors, such as differences in listing characteristics (*log_price_mean* or *year_built_to_now*) or economic conditions (*employment_rate*). Since the interaction term is statistically different from zero, we **fail to reject** the null hypothesis. The control variables provide further insights into factors influencing listing average reviews. For every unit increase in *price_mean*, listing average reviews increase by 0.75 units, suggesting that higher prices may be associated with higher perceived quality or guest satisfaction. For every unit increase in *year_built_to_now* (indicating older properties), listing average reviews decrease by 0.025 units, possibly reflecting a preference for older, more established properties. For every unit increase in *employment_rate*, listing average reviews increase by 14.8 units, highlighting the potential influence of local economic conditions on guest experiences. While the Plus program might not have achieved its intended effects, other property and market characteristics play a significant role in shaping outcomes.

```{r , results = 'asis'}
plm.fe1_br <- plm(booking_rate ~ time + group + time*group, 
             data = data_clean, 
             model = "within", 
             index = c("city_name", "date"))
plm.fe2_br <- plm(booking_rate ~ time + group + time*group + employment_rate + log_price_mean + year_built_to_now,
               data = data_clean,
               model = "within",
               index = c("city_name", "date"))
plm.fe1_li <- plm(listing_avg_review ~ time + group + time*group, 
             data = data_clean, 
             model = "within", 
             index = c("city_name", "date"))
plm.fe2_li <- plm(listing_avg_review ~ time + group + time*group + log_price_mean + year_built_to_now + employment_rate,
               data = data_clean,
               model = "within",
               index = c("city_name", "date"))
stargazer(plm.fe1_br, plm.fe2_br, plm.fe1_li, plm.fe2_li,
          type = "latex", 
          no.space = TRUE, 
          header = FALSE, 
          font.size = "tiny",
          title = "Fixed Effects Regression Results",
          column.labels = c("BR (no controls)", "BR (with controls)", "LAR (no controls)", "LAR (with controls)"),
          dep.var.labels = c("Booking Rate", "Listing Avg Review"))
```


# 4. Assumptions and Model Diagnostics

### 1. Linearity
For the scope of this research, linearity of the panel data model was assumed. Future work should assess linearity to validate model assumptions, though achieving it may be challenging due to demographic and economic variability across cities.

### 2. Random Sampling
The non-random selection of treated cities, geographic bias, and staggered program implementation challenge the random sampling assumption. Efforts to address this included imputing missing data, treating outliers in listing_avg_review and employment_rate, truncating booking_rate and reviews at the 5th and 95th percentiles, and log-transforming price_mean, but significant biases likely remain.

### 3. Multicollinearity
While no severe multicollinearity issues are evident, moderate correlations (year_built_to_now and listing_avg_review vs. zipcode) may still affect the model's interpretation. The Variance Inflation Factor (VIF) diagnostics confirm this assumption was not violated as all VIF results are below 5, indicating low predictors' multicollinearity.

```{r, fig.height = 3.5, fig.width = 7}
# Correlation Table between Numeric Variables
numeric_vars <- data_clean %>%
dplyr::select(booking_rate,zipcode,timeperiod,city_number,log_price_mean,employment_rate,listing_avg_review,year_built_to_now)
correlation_matrix <- round(cor(numeric_vars, use = "complete.obs"), 2)
ggcorr(numeric_vars, label = TRUE, label_round = 2, label_size = 3, hjust = 0.9, layout.exp = 1.5)
```
```{r, results = "hide"}
#Extracting the formula and data from the plm models and doing VIF test
formula <- formula(plm.fe2_br)
data <- model.frame(plm.fe2_br)
lm_model <- lm(formula, data = data)
vif_values <- vif(lm_model)
print(vif_values)

formula <- formula(plm.fe2_li)
data <- model.frame(plm.fe2_li)
lm_model <- lm(formula, data = data)
vif_values <- vif(lm_model)
print(vif_values)
```

### 4. Zero conditional mean

The assumption of zero conditional mean is challenged by omitted variable bias, as unobserved factors likely influence booking rates and average reviews beyond the study's scope. Potential measurement errors were noted in **employment_rate**, which may not reflect monthly fluctuations; **price_mean**, affected by price volatility and promotions; and **year_built_to_now**, susceptible to inaccurate or misreported property records. Simultaneity is also a concern, as dependent variables like booking rates and reviews may influence independent factors such as employment, housing construction, and pricing. These issues highlight the complexity of fully isolating causal relationships in this analysis.

### 5. Homoscedasticity
The studentized Breusch-Pagan test checks if the error term has the same variance given any values of the explanatory variable. The results of the test showed very small p-values for all models, indicating a violation of the homoscedasticity assumption. This violation can be attributed to inherent differences between cities, such as variations in population size, economic conditions, tourism activity, and other contextual factors. 

```{r, results = "hide"}
# Perform Breusch-Pagan tests
bptest_fe1_br <- bptest(plm.fe1_br)
bptest_fe2_br <- bptest(plm.fe2_br)
bptest_fe1_li <- bptest(plm.fe1_li)
bptest_fe2_li <- bptest(plm.fe2_li)

# Extract results into a data frame
bptest_results <- data.frame(
  Model = c("plm.fe1_br", "plm.fe2_br", "plm.fe1_li", "plm.fe2_li"),
  Statistic = c(bptest_fe1_br$statistic, bptest_fe2_br$statistic, bptest_fe1_li$statistic, bptest_fe2_li$statistic),
  DF = c(bptest_fe1_br$parameter, bptest_fe2_br$parameter, bptest_fe1_li$parameter, bptest_fe2_li$parameter),
  P_Value = c(bptest_fe1_br$p.value, bptest_fe2_br$p.value, bptest_fe1_li$p.value, bptest_fe2_li$p.value)
)

# Print the results table
print(bptest_results)
```


### 6. Normality of Residuals
```{r, fig.width = 10}
par(mfrow = c(1, 2))  # 1 row, 2 columns
# Extract residuals from the fixed effects model for booking_rate
residuals_fe2_br <- residuals(plm.fe2_br)
# Extract residuals from the fixed effects model for listing_avg_review
residuals_fe2_li <- residuals(plm.fe2_li)

# Since the Shapiro-Wilk test is limited to samples of size <= 5000, we'll take a random sample of the residuals.
# For model plm.fe2_br
set.seed(123)
sample_residuals_br <- sample(residuals_fe2_br, size = 5000)
shapiro_test_br <- shapiro.test(sample_residuals_br)

# Q-Q Plot for Residuals of plm.fe2_br
qqnorm(sample_residuals_br, main = "Q-Q Plot of Residuals (booking_rate model)")
qqline(sample_residuals_br, col = "red")

# For model plm.fe2_li
set.seed(456)
sample_residuals_li <- sample(residuals_fe2_li, size = 5000)
shapiro_test_li <- shapiro.test(sample_residuals_li)

# Q-Q Plot for Residuals of plm.fe2_li
qqnorm(sample_residuals_li, main = "Q-Q Plot of Residuals (listing_avg_review model)")
qqline(sample_residuals_li, col = "red")

par(mfrow = c(1, 1))  # Back to default (single plot)
```
The Q-Q plots for both models, booking_rate and listing_avg_review, show that the residuals in the central area (approx. between -2.5 and +2) are close to the normal distribution. In the extreme areas, the points deviate slightly from the line - for very negative values they are slightly above, for very positive values slightly below. Such deviations are common in large samples and hardly affect the analysis.
The Shapiro-Wilk tests resulted in very small p-values (p < 0.0001), which indicates statistically significant deviations from the normal distribution. However, the W values are close to 1 (0.99688 for booking_rate and 0.99342 for listing_avg_review), which means a good approximation to the normal distribution. Significant p-values are to be expected for large samples, as the test is very sensitive to small deviations. The normality assumption of the residuals is fulfilled in the central area, where the majority of the data lies. The slight deviations in the extreme ranges are tolerable and do not significantly affect the estimates of the regression coefficients or the statistical inference. Overall, the models are reliable and the results remain valid.

# 5. Discussion and Business Implications

This study examined the impact of the Airbnb Plus program on booking rates and customer satisfaction across various U.S. cities. The analysis revealed no statistically significant impact of the program on booking rates in treated cities compared to control cities. While treated cities experienced stabilization in booking rates, these changes appear to be driven more by external factors such as market conditions and property characteristics than the introduction of the Plus program itself. Interestingly, the program was associated with a slight decrease in average reviews, suggesting potential mismatches between customer expectations and actual experiences. Higher pricing for Plus-certified listings likely led to elevated customer expectations, making them more critical in reviews when expectations were unmet. Higher prices negatively influenced booking rates, which is in line with business expectations. However, higher prices correlated with improved customer satisfaction, possibly due to better property matching and higher quality expectations. Older buildings tended to have higher booking rates, possibly reflecting unique charm or historical value. Conversely, these older properties were associated with lower customer satisfaction, potentially due to reliability or maintenance issues. Cities with higher employment rates showed significantly higher booking rates, indicating economic factors play a critical role in driving demand. This study faced several limitations, including potential non-linear relationships in the data, geographic and temporal biases from the non-random selection of treated cities, and omitted variable bias due to unobserved factors affecting booking rates and customer satisfaction. Measurement errors in variables such as employment rate and average price, as well as heteroscedasticity caused by city-specific variations, further impacted the analysis. However, residuals closely approximated normality in the central ranges, enhancing the reliability of the regression coefficients and statistical inferences. Future research could address these limitations by exploring non-linear modeling techniques and accounting for more unobserved factors to improve explanatory power. However, building on previous research, this study concludes that the Airbnb Plus program is not a worthy investment for the company. If further research on the topic were to be conducted, this study suggests exploring the impact of booking rates across each treated city, highlighting which socio-economic and seasonal factors enhance the program's success. By doing so, the program could be implemented only in cities that meet these requirements, thereby boosting Airbnb's revenue. These cities are expected to be large central business districts (CBDs) with high employment rates, relatively low listing prices, and a good number of historical buildings.

# Disclaimer

This research paper had its code deliberately debugged with the help of AI, making sure that the inevitable human errors were swiftly corrected by our digital assistant. Rest assured, no robots were harmed in the process, and the human touch remained essential. Other than debugging, AI was also used for coding suggestions and alternatives.





